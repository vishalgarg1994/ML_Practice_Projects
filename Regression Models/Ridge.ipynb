{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,KFold,GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_boston()\n",
    "X = df.data\n",
    "y = df.target\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlr = Ridge()\n",
    "'''\n",
    "# Params\n",
    "\n",
    "# alpha(default --> 1.0) ---> Regularization strength; must be a positive float\n",
    "# fit_intercept --> defalut  is true,if false..Line will pass thru Origin\n",
    "# normalize -->Input data will be normalized before fitting...Usually we use standard orMinMax scalreto do our work\n",
    "# copy_X (default --> True) --> Make acopy of X for fitting.Could impact if normalize is True\n",
    "# max_iter ---> Maximum number of iterations for conjugate gradient solve\n",
    "# tol --> Precesion of solution defaultis 0.001\n",
    "# solver ---> ‘auto’, ‘svd’, ‘cholesky’, ‘lsqr’, ‘sparse_cg’, ‘sag’, ‘saga’ ... default is auto\n",
    "\n",
    "‘auto’ chooses the solver automatically based on the type of data.\n",
    "\n",
    "‘svd’ uses a Singular Value Decomposition of X to compute the Ridge coefficients. More stable for singular matrices than ‘cholesky’.\n",
    "\n",
    "‘cholesky’ uses the standard scipy.linalg.solve function to obtain a closed-form solution.\n",
    "\n",
    "‘sparse_cg’ uses the conjugate gradient solver as found in scipy.sparse.linalg.cg. As an iterative algorithm, this solver is more appropriate than ‘cholesky’ for large-scale data (possibility to set tol and max_iter).\n",
    "\n",
    "‘lsqr’ uses the dedicated regularized least-squares routine scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative procedure.\n",
    "\n",
    "‘sag’ uses a Stochastic Average Gradient descent, and ‘saga’ uses its improved, unbiased version named SAGA. Both methods also use an iterative procedure, and are often faster than other solvers when both n_samples and n_features are large. Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 196 candidates, totalling 980 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Using backend LokyBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done 140 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=30)]: Done 390 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=30)]: Done 740 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=30)]: Done 980 out of 980 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nBy default joblib.Parallel uses the 'loky' backend module to start separate Python worker processes to execute tasks \\nconcurrently on separate CPUs. This is a reasonable default for generic Python programs but can induce a significant \\noverhead as the input and output data need to be serialized in a queue for communication with the worker processes \\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ],\n",
    "         'solver':['auto','svd','cholesky','lsqr','sparse_cg','sag','saga']}\n",
    "folds = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "model_cv = GridSearchCV(estimator=rlr,\n",
    "                       param_grid = hyper_params,\n",
    "                       scoring ='neg_mean_absolute_error',\n",
    "                       cv = folds,\n",
    "                       verbose=1,\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=30)\n",
    "model_cv.fit(X_train,y_train)\n",
    "'''\n",
    "By default joblib.Parallel uses the 'loky' backend module to start separate Python worker processes to execute tasks \n",
    "concurrently on separate CPUs. This is a reasonable default for generic Python programs but can induce a significant \n",
    "overhead as the input and output data need to be serialized in a queue for communication with the worker processes \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.526471400593312\n",
      "{'alpha': 1.0, 'solver': 'auto'}\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "      normalize=False, random_state=None, solver='auto', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "print(model_cv.best_score_)\n",
    "print(model_cv.best_params_)\n",
    "print(model_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "      normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rlr = Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
    "rlr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1284272   0.03695233  0.01791436  2.93269454 -7.84806046  4.06357438\n",
      " -0.01724174 -1.27176091  0.22549398 -0.00938149 -0.82710453  0.01198771\n",
      " -0.56347377]\n",
      "26.764544089344003\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# attributes\n",
    "print(rlr.coef_)\n",
    "print(rlr.intercept_)\n",
    "print(rlr.n_iter_) # Actual number of iterations for each target. Available only for sag and lsqr solvers. Other solvers will return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7041586727559436\n",
      "{'alpha': 1.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'normalize': False, 'random_state': None, 'solver': 'auto', 'tol': 0.001}\n",
      "[28.34715071 36.21437831 14.80303493 25.22804634 19.17458952 22.29031648\n",
      " 17.33028278 13.95318273 22.14506024 20.74582213 24.14011309 18.40447565\n",
      " -7.01750315 21.1846762  19.19820978 26.02798498 19.86973569  5.51208138\n",
      " 40.33260217 17.84866562 27.65388459 30.02887972 10.98804148 24.46625789\n",
      " 18.37620309 15.25046005 22.61319214 14.80791284 21.62917267 19.57814764\n",
      " 21.73254632 25.36726035 25.30044412 19.30763226 15.88564352 18.87116841\n",
      " 30.92984029 20.76386724 23.49286646 24.67082407 14.0468997  31.67610639\n",
      " 42.34382119 17.35629744 26.91818696 17.33727443 13.86600737 25.91730843\n",
      " 19.76761959 30.38603367 21.22823089 33.9789751  15.71192385 26.17445031\n",
      " 39.58477186 22.87290593 19.40274082 33.07593414 24.76614616 12.67254167\n",
      " 23.02338367 31.20498451 31.79965924 16.82657749 21.53203533 15.72325795\n",
      " 20.43639171 26.13467468 31.26561709 12.25025516 20.26960392 26.88812912\n",
      " 11.2834432  17.76426079 23.29080816  5.24228688 21.24665934 41.08667425\n",
      " 18.07558606  8.75619058 21.02820122 12.09211883 21.75815187  9.3931167\n",
      " 22.92912381 31.62672341 19.51363091 25.88937392 29.0694624  20.16215225\n",
      " 25.59131342  5.32230164 20.35716028 15.29652528 14.46840302 21.05515356\n",
      " 24.47484485 -1.47167781 14.143591   14.90296428 21.90755507 24.07746287\n",
      " 10.1542658  20.24174522 23.7116239  11.48927313 18.82372104 26.07528937\n",
      " 21.69877046 25.04859055  7.83671185 18.2657803  22.75784476 27.13665874\n",
      " 31.91630548 15.58356398 34.22721027 13.17633389 21.35056917 28.50999992\n",
      " 15.67208975 25.12223518  3.54088611 23.68335629 26.04037546 23.30904878\n",
      " 25.68095606 33.16978343 21.89338852 38.07877624 13.37671226 25.26205711\n",
      " 17.97547011 20.19829229 11.00162795 20.5502153  22.9417886  32.38868871\n",
      " 31.37143215 15.64183812 17.12727676 28.86717628 24.63537062 15.91700345\n",
      "  6.25339694 25.99110604 24.57324997 17.8454672  13.43087291 39.69779239\n",
      " 16.98661426 18.79735745]\n"
     ]
    }
   ],
   "source": [
    "# Methods\n",
    "print(rlr.score(X_test,y_test))\n",
    "print(rlr.get_params())\n",
    "print(rlr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
