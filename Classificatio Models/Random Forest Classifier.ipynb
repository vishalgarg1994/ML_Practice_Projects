{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score,GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "import sklearn.metrics as mx\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_iris()\n",
    "X = df.data\n",
    "y = df.target\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\"\"\"\n",
    "Params: \n",
    "# n_estimators : Number of trees in Forest, Default --> 100\n",
    "# n_jobs : No. of jobs to run in parallel\n",
    "# bootstrap : Whether bootstrap samples are used when building trees. If False, \n",
    "              the whole dataset is used to build each tree.\n",
    "# max_samples(default - True) : If bootstrap is True, the number of samples to draw from \n",
    "                                X to train each base estimator\n",
    "# oob_score(default - False) : Whether to use out-of-bag samples to estimate the generalization accuracy\n",
    "#Criterian : gini, entropy\n",
    "#max_depth : Max depth of tree\n",
    "# min_samples_split : The minimum number of samples required to split an internal node\n",
    "# min_samples_leaf : The minimum number of samples required to be at a leaf node.\n",
    "# max_features : The number of features to consider when looking for the best split\n",
    "# min_weight_fraction_leaf : The minimum weighted fraction of the sum total of weights \n",
    "                             (of all the input samples) required to be at a leaf node.\n",
    "# max_leaf_nodes : Best nodes are defined as relative reduction in impurity\n",
    "# min_impurity_decrease : A node will be split if this split induces a decrease of the impurity greater than or equal to this value\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n",
      "[Parallel(n_jobs=32)]: Done 160 out of 160 | elapsed:   38.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=32,\n",
       "             param_grid=[{'bootstrap': [True, False],\n",
       "                          'criterion': ['gini', 'entropy'],\n",
       "                          'n_estimators': [10, 50, 100, 500],\n",
       "                          'oob_score': [True, False]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_params = [{\n",
    "    'criterion': ['gini','entropy'],\n",
    "    'n_estimators':[10,50,100,500],\n",
    "    'bootstrap' : [True,False],\n",
    "    'oob_score' : [True,False]\n",
    "}]\n",
    "folds = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "model_cv = GridSearchCV(estimator=rf,\n",
    "                       param_grid = hyper_params,\n",
    "                       scoring ='accuracy',\n",
    "                       cv = folds,\n",
    "                       verbose=1,\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=32)\n",
    "model_cv.fit(X_train,y_train)\n",
    "'''\n",
    "By default joblib.Parallel uses the 'loky' backend module to start separate Python worker processes to execute tasks \n",
    "concurrently on separate CPUs. This is a reasonable default for generic Python programs but can induce a significant \n",
    "overhead as the input and output data need to be serialized in a queue for communication with the worker processes \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9238095238095237\n",
      "{'bootstrap': True, 'criterion': 'gini', 'n_estimators': 500, 'oob_score': True}\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "                       n_jobs=None, oob_score=True, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(model_cv.best_score_)\n",
    "print(model_cv.best_params_)\n",
    "print(model_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 500)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10645222 0.04015331 0.44199636 0.41139812]\n",
      "[0 1 2]\n",
      "3\n",
      "4\n",
      "1\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)\n",
    "print(rf.classes_)\n",
    "print(rf.n_classes_)\n",
    "print(rf.n_features_)  # featuresfrom a dataset\n",
    "print(rf.n_outputs_) # output will be only 1 class\n",
    "print(rf.base_estimator_) # print(rf.base_estimator_) \n",
    "print(rf.estimators_)# Willgive all estimator output of 500 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 500, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(rf.get_params())\n",
    "print(rf.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0 0 0 2 1 1 0 0]\n",
      "[[0.    0.996 0.004]\n",
      " [0.954 0.044 0.002]\n",
      " [0.    0.01  0.99 ]\n",
      " [0.    0.978 0.022]\n",
      " [0.    0.86  0.14 ]\n",
      " [0.978 0.02  0.002]\n",
      " [0.    1.    0.   ]\n",
      " [0.    0.068 0.932]\n",
      " [0.    0.858 0.142]\n",
      " [0.002 0.998 0.   ]\n",
      " [0.    0.076 0.924]\n",
      " [1.    0.    0.   ]\n",
      " [0.91  0.088 0.002]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.016 0.884 0.1  ]\n",
      " [0.    0.    1.   ]\n",
      " [0.    1.    0.   ]\n",
      " [0.    0.992 0.008]\n",
      " [0.    0.    1.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.    0.098 0.902]\n",
      " [1.    0.    0.   ]\n",
      " [0.    0.    1.   ]\n",
      " [0.004 0.002 0.994]\n",
      " [0.    0.022 0.978]\n",
      " [0.    0.036 0.964]\n",
      " [0.    0.002 0.998]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.956 0.044 0.   ]\n",
      " [0.004 0.992 0.004]\n",
      " [1.    0.    0.   ]\n",
      " [1.    0.    0.   ]\n",
      " [0.    0.072 0.928]\n",
      " [0.008 0.966 0.026]\n",
      " [0.994 0.004 0.002]\n",
      " [1.    0.    0.   ]\n",
      " [0.996 0.004 0.   ]\n",
      " [0.    0.038 0.962]\n",
      " [0.018 0.902 0.08 ]\n",
      " [0.004 0.988 0.008]\n",
      " [0.99  0.01  0.   ]\n",
      " [0.988 0.01  0.002]]\n"
     ]
    }
   ],
   "source": [
    "print(rf.predict(X_test))\n",
    "print(rf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<1x8164 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 2673 stored elements in Compressed Sparse Row format>,\n",
       " array([   0,   17,   38,   55,   68,   81,  104,  125,  142,  161,  178,\n",
       "         197,  212,  225,  246,  259,  272,  287,  308,  325,  342,  357,\n",
       "         378,  391,  412,  427,  448,  463,  486,  501,  518,  537,  556,\n",
       "         577,  596,  615,  636,  649,  664,  677,  690,  705,  718,  733,\n",
       "         752,  767,  776,  801,  826,  843,  862,  881,  898,  903,  920,\n",
       "         933,  954,  977,  994, 1009, 1022, 1041, 1058, 1069, 1086, 1093,\n",
       "        1110, 1123, 1144, 1157, 1178, 1197, 1220, 1237, 1252, 1271, 1290,\n",
       "        1307, 1324, 1345, 1364, 1387, 1398, 1417, 1434, 1447, 1466, 1479,\n",
       "        1492, 1499, 1520, 1539, 1564, 1583, 1600, 1613, 1620, 1633, 1642,\n",
       "        1661, 1682, 1697, 1718, 1723, 1744, 1757, 1772, 1785, 1806, 1821,\n",
       "        1842, 1857, 1878, 1897, 1912, 1933, 1950, 1967, 1984, 1993, 2008,\n",
       "        2023, 2042, 2057, 2074, 2091, 2114, 2131, 2146, 2157, 2170, 2191,\n",
       "        2202, 2215, 2230, 2249, 2268, 2291, 2300, 2321, 2332, 2347, 2360,\n",
       "        2371, 2384, 2399, 2416, 2435, 2450, 2467, 2486, 2499, 2516, 2537,\n",
       "        2550, 2563, 2572, 2583, 2604, 2621, 2642, 2653, 2666, 2679, 2694,\n",
       "        2711, 2724, 2737, 2756, 2787, 2802, 2821, 2836, 2855, 2874, 2893,\n",
       "        2920, 2935, 2950, 2973, 2998, 3015, 3036, 3049, 3064, 3087, 3100,\n",
       "        3115, 3128, 3149, 3166, 3183, 3194, 3213, 3224, 3243, 3260, 3277,\n",
       "        3290, 3305, 3312, 3333, 3348, 3363, 3380, 3397, 3422, 3431, 3450,\n",
       "        3465, 3482, 3501, 3518, 3537, 3552, 3571, 3582, 3599, 3608, 3625,\n",
       "        3644, 3663, 3684, 3699, 3722, 3733, 3742, 3753, 3766, 3783, 3792,\n",
       "        3807, 3820, 3839, 3850, 3867, 3882, 3897, 3914, 3931, 3942, 3955,\n",
       "        3974, 3985, 4004, 4021, 4050, 4067, 4080, 4099, 4112, 4129, 4142,\n",
       "        4159, 4180, 4197, 4208, 4223, 4242, 4255, 4276, 4293, 4316, 4335,\n",
       "        4346, 4357, 4370, 4393, 4406, 4423, 4438, 4455, 4474, 4489, 4498,\n",
       "        4517, 4536, 4545, 4564, 4583, 4598, 4615, 4632, 4651, 4670, 4677,\n",
       "        4688, 4701, 4716, 4731, 4746, 4761, 4772, 4791, 4798, 4815, 4832,\n",
       "        4849, 4872, 4889, 4908, 4931, 4948, 4963, 4982, 5001, 5014, 5031,\n",
       "        5044, 5061, 5080, 5091, 5108, 5125, 5140, 5153, 5162, 5183, 5198,\n",
       "        5217, 5230, 5247, 5252, 5267, 5286, 5305, 5318, 5337, 5356, 5371,\n",
       "        5388, 5405, 5426, 5447, 5474, 5485, 5502, 5513, 5528, 5539, 5554,\n",
       "        5567, 5586, 5603, 5622, 5641, 5656, 5675, 5694, 5711, 5736, 5747,\n",
       "        5764, 5783, 5798, 5813, 5838, 5849, 5862, 5877, 5892, 5917, 5936,\n",
       "        5963, 5980, 5991, 6004, 6019, 6036, 6051, 6068, 6089, 6116, 6139,\n",
       "        6150, 6159, 6170, 6191, 6214, 6227, 6244, 6257, 6272, 6291, 6312,\n",
       "        6325, 6336, 6349, 6368, 6385, 6402, 6417, 6434, 6447, 6462, 6477,\n",
       "        6504, 6517, 6532, 6549, 6564, 6587, 6604, 6619, 6640, 6659, 6672,\n",
       "        6687, 6708, 6721, 6742, 6755, 6762, 6779, 6796, 6809, 6830, 6855,\n",
       "        6872, 6885, 6902, 6919, 6938, 6953, 6968, 6983, 6998, 7013, 7034,\n",
       "        7047, 7064, 7077, 7088, 7105, 7120, 7133, 7144, 7165, 7178, 7191,\n",
       "        7200, 7221, 7236, 7245, 7262, 7281, 7294, 7311, 7334, 7343, 7362,\n",
       "        7379, 7398, 7411, 7422, 7437, 7450, 7463, 7478, 7485, 7506, 7519,\n",
       "        7538, 7559, 7586, 7599, 7614, 7637, 7654, 7667, 7684, 7703, 7718,\n",
       "        7739, 7752, 7769, 7782, 7793, 7806, 7821, 7836, 7851, 7870, 7883,\n",
       "        7900, 7915, 7936, 7951, 7960, 7977, 7988, 8013, 8026, 8041, 8056,\n",
       "        8081, 8100, 8109, 8130, 8151, 8164], dtype=int32))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.decision_path(X_train[1].reshape(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
