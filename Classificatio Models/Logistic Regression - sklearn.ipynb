{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "import sklearn.metrics as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_iris()\n",
    "X = df.data\n",
    "y = df.target\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=0.7,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Penalty is for regularization..there are different solvers for LogisticRegression\\n   a) Newton-cg,sag,lbfgs ---> support l2 regularization, none as well\\n   b) saga ---> support 'elasticnet',l2 and in latest version it supports the L1 regularization as well none as well\\n   c) liblinear ---> Doesn't support none\\n# dual --> 'False'. dual or primal formulation. If # rows> #cols keepdualas false\\n# tol -->Tolerance for stopping criteria default 10e-4\\n# fit_intercept: Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function\\n# solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\\n# max_iterint, default=100 Maximum number of iterations taken for the solvers to converge.\\n# n_jobsint, default=None\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "'''\n",
    "# Penalty is for regularization..there are different solvers for LogisticRegression\n",
    "   a) Newton-cg,sag,lbfgs ---> support l2 regularization, none as well\n",
    "   b) saga ---> support 'elasticnet',l2 and in latest version it supports the L1 regularization as well none as well\n",
    "   c) liblinear ---> Doesn't support none\n",
    "# dual --> 'False'. dual or primal formulation. If # rows> #cols keepdualas false\n",
    "# tol -->Tolerance for stopping criteria default 10e-4\n",
    "# C ----> Inverse of regularization strength; must be a positive float. Like in support vector machines,\n",
    "          smaller values specify stronger regularization.\n",
    "# fit_intercept: Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function\n",
    "# solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\n",
    "# max_iterint, default=100 Maximum number of iterations taken for the solvers to converge.\n",
    "# n_jobsint, default=None\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:   19.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=12,\n",
       "             param_grid=[{'C': [1, 10, 100, 1000],\n",
       "                          'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                     'saga']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_params = [{\n",
    "    'solver': ['newton-cg','lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'C':[1,10,100,1000]\n",
    "}]\n",
    "folds = KFold(n_splits=5,shuffle=True,random_state=42)\n",
    "model_cv = GridSearchCV(estimator=lr,\n",
    "                       param_grid = hyper_params,\n",
    "                       scoring ='accuracy',\n",
    "                       cv = folds,\n",
    "                       verbose=1,\n",
    "                       return_train_score=True,\n",
    "                       n_jobs=12)\n",
    "model_cv.fit(X_train,y_train)\n",
    "'''\n",
    "By default joblib.Parallel uses the 'loky' backend module to start separate Python worker processes to execute tasks \n",
    "concurrently on separate CPUs. This is a reasonable default for generic Python programs but can induce a significant \n",
    "overhead as the input and output data need to be serialized in a queue for communication with the worker processes \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9619047619047618\n",
      "{'C': 1, 'solver': 'newton-cg'}\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(model_cv.best_score_)\n",
    "print(model_cv.best_params_)\n",
    "print(model_cv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.40471739  0.86855295 -2.27790762 -0.95758355]\n",
      " [ 0.46656108 -0.37541401 -0.18769284 -0.72035824]\n",
      " [-0.06184369 -0.49313893  2.46560046  1.67794179]]\n",
      "[0 1 2]\n",
      "[  8.86221326   2.21020683 -11.07242008]\n",
      "[16]\n"
     ]
    }
   ],
   "source": [
    "lr1 = LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='newton-cg', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "lr1.fit(X_train,y_train)\n",
    "print(lr1.coef_)\n",
    "print(lr1.classes_)\n",
    "print(lr1.intercept_)\n",
    "print(lr1.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40471739,  0.86855295, -2.27790762, -0.95758355],\n",
       "       [ 0.46656108, -0.37541401, -0.18769284, -0.72035824],\n",
       "       [-0.06184369, -0.49313893,  2.46560046,  1.67794179]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# The tol parameter tells the optimization algorithm when to stop. If the value of tol is too big, the algorithm stops before\n",
    "  it can converge. The Best tolerance is where your fetures cofficent doesn't flactuate much.\n",
    "  \n",
    "# Inverse regularization parameter - A control variable that retains strength modification of Regularization by being inversely positioned to the Lambda regulator.\n",
    "Given how Scikit cites it as being:\n",
    "C = 1/λ\n",
    "\n",
    "newton-cg — A newton method. Newton methods use an exact Hessian matrix. It's slow for large datasets, because it computes\n",
    "            the second derivatives.\n",
    "\n",
    "lbfgs — Stands for Limited-memory Broyden–Fletcher–Goldfarb–Shanno. It approximates the second derivative matrix updates \n",
    "        with gradient evaluations. It stores only the last few updates, so it saves memory. It isn't super fast with large data sets.\n",
    "        It will be the default solver as of Scikit-learn version 0.22.0.\n",
    "\n",
    "liblinear — Library for Large Linear Classification. Uses a coordinate descent algorithm. Coordinate descent is based on\n",
    "             minimizing a multivariate function by solving univariate optimization problems in a loop. In other words, it moves \n",
    "            toward the minimum in one direction at a time. It is the default solver for Scikit-learn versions earlier than 0.22.0.\n",
    "            It performs pretty well with high dimensionality. It does have a number of drawbacks. It can get stuck, is unable to run \n",
    "            in parallel, and can only solve multi-class logistic regression with one-vs.-rest.\n",
    "\n",
    "sag — Stochastic Average Gradient descent. A variation of gradient descent and incremental aggregated gradient approaches that uses\n",
    "      a random sample of previous gradient values. Fast for big datasets.\n",
    "\n",
    "saga — Extension of sag that also allows for L1 regularization. Should generally train faster than sag.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1,\n",
       "       2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 2, 0, 2, 0, 0,\n",
       "       2, 1, 2, 2, 2, 2, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1,\n",
       "       2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0,\n",
       "       2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0, 1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Part\n",
    "y_pred = lr1.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.15028286e-02, 9.45095515e-01, 1.34016561e-02],\n",
       "       [7.75324069e-04, 4.52776923e-01, 5.46447753e-01],\n",
       "       [1.21718958e-04, 1.32293705e-01, 8.67584576e-01],\n",
       "       [6.61302910e-03, 8.84155388e-01, 1.09231582e-01],\n",
       "       [1.91554057e-06, 9.28625608e-03, 9.90711828e-01],\n",
       "       [2.01722394e-02, 8.96393042e-01, 8.34347186e-02],\n",
       "       [1.97933875e-07, 7.41735231e-03, 9.92582450e-01],\n",
       "       [1.04035426e-02, 7.34509510e-01, 2.55086947e-01],\n",
       "       [9.73106785e-01, 2.68930789e-02, 1.35927506e-07],\n",
       "       [1.17975958e-07, 7.44535388e-03, 9.92554528e-01],\n",
       "       [2.01734531e-02, 9.47826351e-01, 3.20001956e-02],\n",
       "       [9.66980993e-01, 3.30188470e-02, 1.60174408e-07],\n",
       "       [9.79387839e-01, 2.06120543e-02, 1.07068621e-07],\n",
       "       [9.46304378e-01, 5.36940272e-02, 1.59486390e-06],\n",
       "       [5.83732204e-02, 9.31025102e-01, 1.06016772e-02],\n",
       "       [8.63522657e-04, 4.03695118e-01, 5.95441360e-01],\n",
       "       [9.35865044e-01, 6.41335075e-02, 1.44832106e-06],\n",
       "       [9.33125169e-01, 6.68741889e-02, 6.42538930e-07],\n",
       "       [9.33489873e-01, 6.65085606e-02, 1.56651140e-06],\n",
       "       [1.70992842e-02, 8.93167163e-01, 8.97335524e-02],\n",
       "       [9.62859519e-01, 3.71402332e-02, 2.47659642e-07],\n",
       "       [2.37571771e-02, 9.10357210e-01, 6.58856129e-02],\n",
       "       [2.72416196e-07, 5.19615258e-03, 9.94803575e-01],\n",
       "       [9.74693633e-01, 2.53061941e-02, 1.72573251e-07],\n",
       "       [1.06886554e-02, 9.04982183e-01, 8.43291618e-02],\n",
       "       [4.05382472e-04, 1.86226494e-01, 8.13368123e-01],\n",
       "       [9.83871170e-01, 1.61287697e-02, 6.07694989e-08],\n",
       "       [2.17666324e-03, 4.37725960e-01, 5.60097377e-01],\n",
       "       [4.12566741e-04, 1.94059350e-01, 8.05528083e-01],\n",
       "       [1.14140516e-02, 9.64747744e-01, 2.38382048e-02],\n",
       "       [1.20184284e-02, 7.12829342e-01, 2.75152230e-01],\n",
       "       [9.21094890e-05, 5.29015738e-02, 9.47006317e-01],\n",
       "       [1.77856767e-02, 9.22001258e-01, 6.02130656e-02],\n",
       "       [9.58920694e-01, 4.10787010e-02, 6.05333227e-07],\n",
       "       [1.20824993e-01, 8.73527077e-01, 5.64792925e-03],\n",
       "       [1.35139252e-04, 1.62858516e-01, 8.37006344e-01],\n",
       "       [9.68536373e-01, 3.14634553e-02, 1.71651270e-07],\n",
       "       [9.76353332e-01, 2.36465911e-02, 7.67820580e-08],\n",
       "       [3.28787699e-02, 9.44915570e-01, 2.22056598e-02],\n",
       "       [8.34039544e-04, 4.57849652e-01, 5.41316308e-01],\n",
       "       [9.55052219e-01, 4.49474363e-02, 3.45104307e-07],\n",
       "       [1.46350959e-04, 6.84421990e-02, 9.31411450e-01],\n",
       "       [9.65852690e-01, 3.41470703e-02, 2.40055903e-07],\n",
       "       [9.59409969e-01, 4.05890713e-02, 9.59652013e-07],\n",
       "       [2.99320884e-03, 4.30189037e-01, 5.66817754e-01],\n",
       "       [2.28532266e-01, 7.68826960e-01, 2.64077470e-03],\n",
       "       [1.35583155e-05, 3.44052072e-02, 9.65581234e-01],\n",
       "       [6.79881629e-04, 3.54522871e-01, 6.44797248e-01],\n",
       "       [1.12832949e-04, 1.97146955e-01, 8.02740212e-01],\n",
       "       [1.19694592e-06, 1.80452627e-02, 9.81953540e-01],\n",
       "       [2.27273831e-02, 9.18673007e-01, 5.85996099e-02],\n",
       "       [9.69294651e-01, 3.07051082e-02, 2.41097172e-07],\n",
       "       [9.86802574e-01, 1.31973873e-02, 3.83226035e-08],\n",
       "       [6.00102783e-04, 4.61828943e-01, 5.37570954e-01],\n",
       "       [1.07322431e-05, 5.88090515e-02, 9.41180216e-01],\n",
       "       [9.65029264e-01, 3.49704211e-02, 3.14623602e-07],\n",
       "       [9.72478914e-01, 2.75209095e-02, 1.76801706e-07],\n",
       "       [9.77807357e-01, 2.21925110e-02, 1.32082152e-07],\n",
       "       [1.03091694e-03, 5.75632543e-01, 4.23336540e-01],\n",
       "       [2.72204524e-05, 2.65310851e-02, 9.73441694e-01],\n",
       "       [9.79690270e-01, 2.03095578e-02, 1.71940626e-07],\n",
       "       [4.43871146e-05, 8.31240955e-02, 9.16831517e-01],\n",
       "       [2.79114662e-06, 7.27909164e-03, 9.92718117e-01],\n",
       "       [9.77532521e-01, 2.24673675e-02, 1.11460104e-07],\n",
       "       [3.99166523e-03, 7.31883543e-01, 2.64124791e-01],\n",
       "       [3.16565090e-03, 7.73852076e-01, 2.22982273e-01],\n",
       "       [1.49286989e-03, 4.58311657e-01, 5.40195473e-01],\n",
       "       [2.96364843e-03, 8.19582064e-01, 1.77454288e-01],\n",
       "       [1.02993056e-04, 7.32694905e-02, 9.26627516e-01],\n",
       "       [9.71907656e-01, 2.80921113e-02, 2.33010314e-07],\n",
       "       [7.64909817e-05, 1.11974137e-01, 8.87949372e-01],\n",
       "       [1.76906843e-02, 8.66458192e-01, 1.15851124e-01],\n",
       "       [2.37889323e-04, 1.78934610e-01, 8.20827500e-01],\n",
       "       [6.65926850e-02, 9.26615310e-01, 6.79200501e-03],\n",
       "       [4.42503537e-02, 8.92250774e-01, 6.34988721e-02],\n",
       "       [5.94172448e-03, 7.80546368e-01, 2.13511907e-01],\n",
       "       [9.42887434e-01, 5.71121209e-02, 4.45003675e-07],\n",
       "       [3.80011610e-03, 8.53495062e-01, 1.42704822e-01],\n",
       "       [1.07580322e-02, 8.65215908e-01, 1.24026059e-01],\n",
       "       [9.69354225e-01, 3.06455977e-02, 1.77477732e-07],\n",
       "       [3.09102672e-02, 9.01999520e-01, 6.70902130e-02],\n",
       "       [1.71556200e-06, 2.78871576e-02, 9.72111127e-01],\n",
       "       [2.77370538e-05, 4.97932595e-02, 9.50179003e-01],\n",
       "       [9.72905108e-01, 2.70946106e-02, 2.81753316e-07],\n",
       "       [1.45121807e-01, 8.49157655e-01, 5.72053707e-03],\n",
       "       [9.97192960e-06, 1.96833805e-02, 9.80306648e-01],\n",
       "       [3.25358599e-05, 1.43551152e-01, 8.56416312e-01],\n",
       "       [9.80372393e-01, 1.96275209e-02, 8.57352368e-08],\n",
       "       [1.56932230e-05, 3.14776853e-02, 9.68506621e-01],\n",
       "       [9.58548302e-01, 4.14514507e-02, 2.46982881e-07],\n",
       "       [1.49182466e-03, 6.66078647e-01, 3.32429529e-01],\n",
       "       [2.83918000e-06, 3.84417826e-02, 9.61555378e-01],\n",
       "       [6.20798936e-05, 9.77505585e-02, 9.02187362e-01],\n",
       "       [2.23311306e-02, 9.11807161e-01, 6.58617084e-02],\n",
       "       [1.02078932e-04, 1.37082184e-01, 8.62815738e-01],\n",
       "       [3.69206607e-03, 8.86647973e-01, 1.09659961e-01],\n",
       "       [9.07157426e-03, 9.14277219e-01, 7.66512071e-02],\n",
       "       [9.63289870e-04, 2.26591222e-01, 7.72445488e-01],\n",
       "       [7.25747597e-04, 2.50431034e-01, 7.48843218e-01],\n",
       "       [9.29285838e-01, 7.07134774e-02, 6.84116325e-07],\n",
       "       [1.99807197e-02, 9.37957395e-01, 4.20618849e-02],\n",
       "       [7.11845440e-03, 5.33404900e-01, 4.59476645e-01],\n",
       "       [9.82342067e-01, 1.76578989e-02, 3.41933606e-08],\n",
       "       [2.07532675e-02, 9.39481156e-01, 3.97655767e-02],\n",
       "       [6.31804653e-06, 3.54550224e-02, 9.64538660e-01]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob =  lr1.predict_proba(X_train)\n",
    "y_pred_prob\n",
    "# Since there are three classes so it will give prob of every class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
